{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa81cdd7-a9d0-44f2-8481-170f3b1cd42d",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "The metrics we will use are:\n",
    "\n",
    "**1. Style Transfer Intensity (STI)**\n",
    "\n",
    "The STI metric is used to measure how much a\n",
    "style transfer model has changed the style of a text sample.\n",
    "\n",
    "**2. Content Preservation Score (CPS)**\n",
    "\n",
    "The CPS metric is used to measure how well a\n",
    "style transfer model preserves the original content of a text sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f76c9ec-7a01-4770-8304-fa76c7e4aee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshvigupta/Library/Caches/pypoetry/virtualenvs/debiasing-text-with-style-transfer-2Fg498RO-py3.9/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import wasserstein_distance\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "\n",
    "#BERT model\n",
    "CLS_MODEL_PATH = \"C:/Users/athar/OneDrive/Desktop/Rutgers/NLP/model\"\n",
    "model_sc = AutoModelForSequenceClassification.from_pretrained(CLS_MODEL_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(CLS_MODEL_PATH)\n",
    "\n",
    "# Calculate Content Preservation Score\n",
    "model_st = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "cls_explainer = SequenceClassificationExplainer(model_sc, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6661169f-a690-4487-9f6b-fe99324e665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = '../data/data_for_eval.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the column names match CSV file's column names\n",
    "source_label_0_col = 'source_label_0'\n",
    "source_label_1_col = 'source_label_1'\n",
    "target_label_0_col = 'target_label_0'\n",
    "target_label_1_col = 'target_label_1'\n",
    "predicted_label_0_col = 'predicted_label_0'  \n",
    "predicted_label_1_col = 'predicted_label_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbca770-3c38-4e18-8af6-07ce1688bc67",
   "metadata": {},
   "source": [
    "## For Style Transfer Intensity (STI) calculation using Earth Mover's Distance\n",
    "1. EMD Calculation\n",
    "\n",
    "EMD is calculated between the style distributions (probabilities) of the source text and the predicted text, as well as between the target text and the predicted text.\n",
    "\n",
    "2. Style Distributions\n",
    "\n",
    "The style distribution for each text type (source, target, predicted) is represented by the probabilities that the text is neutral or subjective. These are stored in the columns like source_label_0, source_label_1, etc.\n",
    "\n",
    "3. EMD for Source-Predicted\n",
    "\n",
    "For each pair of source and predicted texts, EMD measures how much the style of the text has shifted after the style transfer. A lower EMD indicates a smaller shift, suggesting that the predicted text retains much of the source text's style.\n",
    "\n",
    "4. EMD for Target-Predicted\n",
    "\n",
    "Similarly, EMD between the target and predicted texts measures how close the style of the predicted text is to the desired target style. A lower EMD here indicates that the predicted text closely matches the target style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee10cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMD for Style Transfer Intensity (STI)\n",
    "\n",
    "# Here, 'source_label_0' and 'source_label_1' are the probabilities for the source text being neutral and subjective, respectively\n",
    "# Similarly for 'target_label_0', 'target_label_1', 'predicted_label_0', and 'predicted_label_1'\n",
    "\n",
    "emd_source_predicted = [wasserstein_distance([row[source_label_0_col], row[source_label_1_col]],\n",
    "                                              [row[predicted_label_0_col], row[predicted_label_1_col]])\n",
    "                        for index, row in df.iterrows()]\n",
    "emd_target_predicted = [wasserstein_distance([row[target_label_0_col], row[target_label_1_col]],\n",
    "                                              [row[predicted_label_0_col], row[predicted_label_1_col]])\n",
    "                        for index, row in df.iterrows()]\n",
    "emd_source_target = [wasserstein_distance([row[target_label_0_col], row[target_label_1_col]],\n",
    "                                              [row[source_label_0_col], row[source_label_1_col]])\n",
    "                        for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493dca1a-ff6d-4911-b85a-d6beec1b173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Calculate Content Preservation Score\n",
    "# model_st = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "# source_embeddings = model_st.encode(df['source_text'].tolist())\n",
    "# predicted_embeddings = model_st.encode(df['predictions'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becbaa40-3815-4d02-93f3-71058d78f306",
   "metadata": {},
   "source": [
    "## For Content Preservation Score (CPS) calculation\n",
    "\n",
    "**1. Compute Sentence Embeddings**\n",
    "\n",
    "SentenceTransformer Model: The code uses a pre-trained model from the sentence-transformers library, specifically 'bert-base-nli-mean-tokens'. This model is designed to produce meaningful sentence embeddings for a wide range of texts.\n",
    "\n",
    "Embeddings for Source and Predicted Texts: The model encodes both the source and predicted texts, converting them into high-dimensional vectors (embeddings) that represent their semantic content.\n",
    "\n",
    "**2. Calculate Cosine Similarity for Content Preservation**\n",
    "\n",
    "Cosine Similarity: This metric measures the cosine of the angle between two vectors. In the context of sentence embeddings, a higher cosine similarity indicates greater semantic similarity between texts.\n",
    "\n",
    "Iterative Comparison: The code iterates over each pair of source and predicted embeddings, calculating the cosine similarity for each pair. This value ranges from -1 to 1, where 1 means identical directionality (high semantic similarity), 0 indicates orthogonality (no similarity), and -1 implies completely opposite directionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2aa2c6a-84a8-41b4-8cf0-0265e886a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_scores = [1 - cosine(source_emb, pred_emb) \n",
    "                  if not np.isnan(cosine(source_emb, pred_emb)) else 0\n",
    "                  for source_emb, pred_emb in zip(source_embeddings, predicted_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804ae208-a99a-479c-b892-bfc312e6f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results in a new DataFrame\n",
    "evaluation_df = pd.DataFrame({\n",
    "    \"Source Text\": df['source_text'],\n",
    "    \"Target Text\": df['target_text'],\n",
    "    \"Predicted Text\": df['predictions'],\n",
    "    \"EMD Source-Predicted\": emd_source_predicted,\n",
    "    \"EMD Target-Predicted\": emd_target_predicted,\n",
    "\t\"EMD Source-Target\": emd_source_target,\n",
    "    \"Content Preservation Score\": content_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db78b7c7-fa47-4261-9812-eff078bdce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Source Text  \\\n",
      "0  in april 2009 a brazilian human rights group, ...   \n",
      "1  the 51 day standoff and ensuing murder of 76 m...   \n",
      "2  mark oaten (born 8 march 1964, watford) is a d...   \n",
      "3  another infamous period of colonisation in anc...   \n",
      "4  photo sequence of astonishing 2005 chicagoland...   \n",
      "\n",
      "                                         Target Text  \\\n",
      "0  in april 2009 a brazilian human rights group, ...   \n",
      "1  the 51 day standoff and ensuing deaths of 76 m...   \n",
      "2  mark oaten (born 8 march 1964, watford) is a l...   \n",
      "3  another period of colonisation in ancient time...   \n",
      "4  photo sequence of 2005 chicagoland crash with ...   \n",
      "\n",
      "                                      Predicted Text  EMD Source-Predicted  \\\n",
      "0  in april 2009 a brazilian human rights group, ...              0.000000   \n",
      "1  the 51 day standoff and ensuing murder of 76 m...              0.000000   \n",
      "2  mark oaten (born 8 march 1964, watford) is a l...              0.037568   \n",
      "3  another period of colonisation in ancient time...              0.025609   \n",
      "4  photo sequence of 2005 chicagoland crash with ...              0.001016   \n",
      "\n",
      "   EMD Target-Predicted  EMD Source-Target  Content Preservation Score  \n",
      "0              0.097619           0.097619                    1.000000  \n",
      "1              0.148595           0.148595                    1.000000  \n",
      "2              0.000000           0.037568                    0.934390  \n",
      "3              0.000000           0.025609                    0.851425  \n",
      "4              0.000000           0.001016                    0.983531  \n"
     ]
    }
   ],
   "source": [
    "print(evaluation_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489ab745-b30f-40c7-b538-65b965aca2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the evaluation DataFrame to a new CSV file\n",
    "# evaluation_csv_path = \"../../data/evaluated.csv\"\n",
    "# evaluation_df.to_csv(evaluation_csv_path, index=False)\n",
    "\n",
    "# print(\"Evaluation data saved to:\", evaluation_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "852f294d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source Text                   mark oaten (born 8 march 1964, watford) is a d...\n",
       "Target Text                   mark oaten (born 8 march 1964, watford) is a l...\n",
       "Predicted Text                mark oaten (born 8 march 1964, watford) is a l...\n",
       "EMD Source-Predicted                                                   0.037568\n",
       "EMD Target-Predicted                                                        0.0\n",
       "EMD Source-Target                                                      0.037568\n",
       "Content Preservation Score                                              0.93439\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666caab8",
   "metadata": {},
   "source": [
    "We Need to combine the SWD metrics into a single STI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9bff41",
   "metadata": {},
   "source": [
    "This statement has been successfully neutralized by the model (EMD Target-Predicted = 0). However, CPS shows value 0.93. This is due to the blant cosine similarity matching between source and oredicted text. The style transferred word is reducing the CPS score.\n",
    "Thereofre we need to remove that Word to make CPS more appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf296b",
   "metadata": {},
   "source": [
    "Therefore we will refine evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a279790",
   "metadata": {},
   "source": [
    "# Refined Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "738221c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_renamed = df.rename(columns={\"source_text\":\"source_text\",\"source_label_0\":\"source_prob_S\",\"source_label_1\":\"source_prob_N\",\"target_text\":\"target_text\",\n",
    "# \t\t   \"target_label_0\":\"target_prob_S\",\"target_label_1\":\"taget_prob_N\",\"predictions\":\"predictions\",\"predicted_label_0\":\"predicted_prob_S\",\"predicted_label_1\":\"predicted_label_N\"})\n",
    "\n",
    "# # Ensure the column names match CSV file's column names\n",
    "# source_label_0_col = 'source_label_0'\n",
    "# source_label_1_col = 'source_label_1'\n",
    "# target_label_0_col = 'target_label_0'\n",
    "# target_label_1_col = 'target_label_1'\n",
    "# predicted_label_0_col = 'predicted_label_0'  \n",
    "# predicted_label_1_col = 'predicted_label_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e73ac",
   "metadata": {},
   "source": [
    "### calculating directional STI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c530a404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Text</th>\n",
       "      <th>Target Text</th>\n",
       "      <th>Predicted Text</th>\n",
       "      <th>EMD Source-Predicted</th>\n",
       "      <th>EMD Target-Predicted</th>\n",
       "      <th>EMD Source-Target</th>\n",
       "      <th>Content Preservation Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in april 2009 a brazilian human rights group, ...</td>\n",
       "      <td>in april 2009 a brazilian human rights group, ...</td>\n",
       "      <td>in april 2009 a brazilian human rights group, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097619</td>\n",
       "      <td>0.097619</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 51 day standoff and ensuing murder of 76 m...</td>\n",
       "      <td>the 51 day standoff and ensuing deaths of 76 m...</td>\n",
       "      <td>the 51 day standoff and ensuing murder of 76 m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148595</td>\n",
       "      <td>0.148595</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mark oaten (born 8 march 1964, watford) is a d...</td>\n",
       "      <td>mark oaten (born 8 march 1964, watford) is a l...</td>\n",
       "      <td>mark oaten (born 8 march 1964, watford) is a l...</td>\n",
       "      <td>0.037568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037568</td>\n",
       "      <td>0.934390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>another infamous period of colonisation in anc...</td>\n",
       "      <td>another period of colonisation in ancient time...</td>\n",
       "      <td>another period of colonisation in ancient time...</td>\n",
       "      <td>0.025609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025609</td>\n",
       "      <td>0.851425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>photo sequence of astonishing 2005 chicagoland...</td>\n",
       "      <td>photo sequence of 2005 chicagoland crash with ...</td>\n",
       "      <td>photo sequence of 2005 chicagoland crash with ...</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.983531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Source Text  \\\n",
       "0  in april 2009 a brazilian human rights group, ...   \n",
       "1  the 51 day standoff and ensuing murder of 76 m...   \n",
       "2  mark oaten (born 8 march 1964, watford) is a d...   \n",
       "3  another infamous period of colonisation in anc...   \n",
       "4  photo sequence of astonishing 2005 chicagoland...   \n",
       "\n",
       "                                         Target Text  \\\n",
       "0  in april 2009 a brazilian human rights group, ...   \n",
       "1  the 51 day standoff and ensuing deaths of 76 m...   \n",
       "2  mark oaten (born 8 march 1964, watford) is a l...   \n",
       "3  another period of colonisation in ancient time...   \n",
       "4  photo sequence of 2005 chicagoland crash with ...   \n",
       "\n",
       "                                      Predicted Text  EMD Source-Predicted  \\\n",
       "0  in april 2009 a brazilian human rights group, ...              0.000000   \n",
       "1  the 51 day standoff and ensuing murder of 76 m...              0.000000   \n",
       "2  mark oaten (born 8 march 1964, watford) is a l...              0.037568   \n",
       "3  another period of colonisation in ancient time...              0.025609   \n",
       "4  photo sequence of 2005 chicagoland crash with ...              0.001016   \n",
       "\n",
       "   EMD Target-Predicted  EMD Source-Target  Content Preservation Score  \n",
       "0              0.097619           0.097619                    1.000000  \n",
       "1              0.148595           0.148595                    1.000000  \n",
       "2              0.000000           0.037568                    0.934390  \n",
       "3              0.000000           0.025609                    0.851425  \n",
       "4              0.000000           0.001016                    0.983531  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89c0f99",
   "metadata": {},
   "source": [
    "Logic : If emd between source and predicted is lesser than the emd between target and predicted, then it is gievn negative sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbfe1527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining intuitive STI  : more 'accurate' style transfer is when prediction is close to target + far away from source.\n",
    "# 1. more intuitive\n",
    "# 2. Focuses on genuine style transfers\n",
    "# 2. penalizes no change in source, target and prediction\n",
    "evaluation_df['STI'] = evaluation_df['EMD Source-Predicted'] + (1/(1+evaluation_df['EMD Target-Predicted']))\n",
    "evaluation_df['STI'] = evaluation_df['STI'] - evaluation_df['STI'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa84b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89dadf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(evaluation_df,x='STI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b191e49",
   "metadata": {},
   "source": [
    "Most texts have STI of 0.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be11e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us check some examples with high STI\n",
    "max_sti_df = evaluation_df.sort_values(by='STI',ascending=False).head(n = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db9875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source text : muzaffarabad is the capital of the pakistani territory of pakistan occupied kashmir.\n",
      "Target Text :  muzaffarabad is the capital of the pakistani territory of pakistan administered kashmir.\n",
      "Predicted Text :  muzaffarabad is the capital of the pakistani territory of pakistan administered kashmir.\n"
     ]
    }
   ],
   "source": [
    "print(\"source text :\" ,max_sti_df['Source Text'].iloc[0])\n",
    "print(\"Target Text : \", max_sti_df['Target Text'].iloc[0])\n",
    "print(\"Predicted Text : \", max_sti_df['Predicted Text'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c49386",
   "metadata": {},
   "source": [
    "Perfect Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d812315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source text : it also has a small concessions stand, run by the fantastic volunteer staff, which sells refreshments and earplugs.\n",
      "Target Text :  it also has a small concessions stand, run by the volunteer staff, which sells refreshments and earplugs.\n",
      "Predicted Text :  it also has a small concessions stand, run by the volunteer staff, which sells refreshments and earplugs.\n"
     ]
    }
   ],
   "source": [
    "print(\"source text :\" ,max_sti_df['Source Text'].iloc[1])\n",
    "print(\"Target Text : \", max_sti_df['Target Text'].iloc[1])\n",
    "print(\"Predicted Text : \", max_sti_df['Predicted Text'].iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83c0d2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source text : he is best known for his metal wall sculptures and looney tunes shadow boxes.\n",
      "Target Text :  he is known for his metal wall sculptures and looney tunes shadow boxes.\n",
      "Predicted Text :  he is known for his metal wall sculptures and looney tunes shadow boxes.\n"
     ]
    }
   ],
   "source": [
    "print(\"source text :\" ,max_sti_df['Source Text'].iloc[3])\n",
    "print(\"Target Text : \", max_sti_df['Target Text'].iloc[3])\n",
    "print(\"Predicted Text : \", max_sti_df['Predicted Text'].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dde057",
   "metadata": {},
   "source": [
    "High STI is when prediction text style matches perfecty with Target Text Style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a8ce9",
   "metadata": {},
   "source": [
    "#Let us look at most common STI examples. (STI = 0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b58913ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_sti_df = evaluation_df[(evaluation_df['STI']>=0.3) & (evaluation_df['STI'] < 0.33)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f90cdb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us check some examples\n",
    "common_sti_df = common_sti_df.sort_values(by='STI',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b94a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source text : kulhawik received her bachelor of arts degree in english & secondary education from simmons college in 1974. one of the top two graduating seniors at simmons, kulhawik received the prestigious crown zellerbach award and a full fellowship from the university of vermont, where she received a double master's degree in english/education in 1977. she taught english at brookline high school from 1976 through 1978, and at the boston architectural center from 1977 through 1979.\n",
      "Target Text :  kulhawik received her bachelor of arts degree in english & secondary education from simmons college in 1974. one of the top two graduating seniors at simmons, kulhawik received the crown zellerbach award and a full fellowship from the university of vermont, where she received a double master's degree in english/education in 1977. she taught english at brookline high school from 1976 through 1978, and at the boston architectural center from 1977 through 1979.\n",
      "Predicted Text :  kulhawik received her bachelor of arts degree in english & secondary education from simmons college in 1974. one of the top two graduating seniors at simmons, kulhawick received the crown zellerbach award and a full fellowship from the university of vermont, where she received a double master's degree in french/education in 1977. she taught english at brookline high school from 1976 through 1978, and at the boston architectural center from 1977 through 1979.\n"
     ]
    }
   ],
   "source": [
    "print(\"source text :\" ,common_sti_df['Source Text'].iloc[3])\n",
    "print(\"Target Text : \", common_sti_df['Target Text'].iloc[3])\n",
    "print(\"Predicted Text : \", common_sti_df['Predicted Text'].iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18e6d6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source text : in recent years, the term has often been misapplied to those who are merely clean-cut.\n",
      "Target Text :  in recent years, the term has often been applied to those who are merely clean-cut.\n",
      "Predicted Text :  in recent years, the term has often been used to describe those who are merely clean-cut.\n"
     ]
    }
   ],
   "source": [
    "print(\"source text :\" ,common_sti_df['Source Text'].iloc[10])\n",
    "print(\"Target Text : \", common_sti_df['Target Text'].iloc[10])\n",
    "print(\"Predicted Text : \", common_sti_df['Predicted Text'].iloc[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3b07b",
   "metadata": {},
   "source": [
    "Minimum STI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf7f41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sti_df = evaluation_df[(evaluation_df['STI']>=0) & (evaluation_df['STI'] < 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5976ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source text : aiming at palestinian qassam rockets and grad launchers in an open area, seven of the shells landed 1 km off target and hit houses in the outskirts of beit hanoun.\n",
      "Target Text :  although israel claimed they aimed at palestinian qassam rockets and grad launchers in an open area, seven of the shells landed 1 km off target and hit houses in the outskirts of beit hanoun.\n",
      "Predicted Text :  aiming at palestinian qassam rockets and grad launchers in an open area, seven of the shells landed 1 km off target and hit houses in the outskirts of beit hanoun.\n"
     ]
    }
   ],
   "source": [
    "print(\"source text :\" ,min_sti_df['Source Text'].iloc[15])\n",
    "print(\"Target Text : \", min_sti_df['Target Text'].iloc[15])\n",
    "print(\"Predicted Text : \", min_sti_df['Predicted Text'].iloc[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000143f7",
   "metadata": {},
   "source": [
    "No change in prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caea8c9",
   "metadata": {},
   "source": [
    "### CPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da1f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers_interpret import SequenceClassificationExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a42f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS_MODEL_PATH = \"../../models/bert_finetuned\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(CLS_MODEL_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(CLS_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65b9ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'This is the greatest movie ever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f626a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_explainer = SequenceClassificationExplainer(model, tokenizer)\n",
    "word_attributions = cls_explainer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb11c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributions(text):\n",
    "\tword_attributions = cls_explainer(text)\n",
    "\t# Create a DataFrame\n",
    "\tdf_attrb = pd.DataFrame(word_attributions, columns=['token', 'score'])\n",
    "\tdf_attrb[\"abs_norm\"] = df_attrb['score'].abs()/df_attrb[\"score\"].abs().sum()\n",
    "\tdf_attrb = df_attrb.sort_values(by='abs_norm',ascending=False)\n",
    "\tdf_attrb['abs_norm'] = df_attrb['abs_norm'].cumsum()\n",
    "\tdf_attrb[\"cumulative\"] = df_attrb[\"abs_norm\"].cumsum()\n",
    "\n",
    "\treturn df_attrb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "750e1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_style_words(text):\n",
    "\tatrrb_df = get_attributions(text)\n",
    "\t#remove the top scoring word\n",
    "\t#if length is less than 3, do not remove any word\n",
    "\tif len(atrrb_df['token']) <= 3:\n",
    "\t\tNone\n",
    "\telse: \n",
    "\t\t#if length more than 3 remove top score word\n",
    "\t\t\n",
    "\t\t#get the max score\n",
    "\t\tmax_score = max(atrrb_df['score'])\n",
    "        #list the words with subjectivity for future use\n",
    "\t\tsubj_wrds = atrrb_df['token'][(atrrb_df['score']>=max_score)]\n",
    "\t\tnon_subj_words = atrrb_df['token'][(atrrb_df['score']<max_score)]\n",
    "\t\tmasked_text = non_subj_words.sort_index()[1:-1].str.cat(sep=' ')\n",
    "\t\t\n",
    "\treturn masked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68f9b150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is the greatest movie'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_style_words(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fed3ac7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (0.97)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>1.45</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> greatest                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(120, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (0.97)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>1.45</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> greatest                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(120, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb621c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
