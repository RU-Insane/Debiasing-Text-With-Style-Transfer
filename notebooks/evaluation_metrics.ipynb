{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa81cdd7-a9d0-44f2-8481-170f3b1cd42d",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "The metrics we will use are:\n",
    "\n",
    "**1. Style Transfer Intensity (STI)**\n",
    "\n",
    "The STI metric is used to measure how much a\n",
    "style transfer model has changed the style of a text sample.\n",
    "\n",
    "**2. Content Preservation Score (CPS)**\n",
    "\n",
    "The CPS metric is used to measure how well a\n",
    "style transfer model preserves the original content of a text sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f76c9ec-7a01-4770-8304-fa76c7e4aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import wasserstein_distance\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6661169f-a690-4487-9f6b-fe99324e665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = '../../data/data_for_eval.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the column names match CSV file's column names\n",
    "source_label_0_col = 'source_label_0'\n",
    "source_label_1_col = 'source_label_1'\n",
    "target_label_0_col = 'target_label_0'\n",
    "target_label_1_col = 'target_label_1'\n",
    "predicted_label_0_col = 'predicted_label_0'  \n",
    "predicted_label_1_col = 'predicted_label_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbca770-3c38-4e18-8af6-07ce1688bc67",
   "metadata": {},
   "source": [
    "## For Style Transfer Intensity (STI) calculation using Earth Mover's Distance\n",
    "1. EMD Calculation\n",
    "\n",
    "EMD is calculated between the style distributions (probabilities) of the source text and the predicted text, as well as between the target text and the predicted text.\n",
    "\n",
    "2. Style Distributions\n",
    "\n",
    "The style distribution for each text type (source, target, predicted) is represented by the probabilities that the text is neutral or subjective. These are stored in the columns like source_label_0, source_label_1, etc.\n",
    "\n",
    "3. EMD for Source-Predicted\n",
    "\n",
    "For each pair of source and predicted texts, EMD measures how much the style of the text has shifted after the style transfer. A lower EMD indicates a smaller shift, suggesting that the predicted text retains much of the source text's style.\n",
    "\n",
    "4. EMD for Target-Predicted\n",
    "\n",
    "Similarly, EMD between the target and predicted texts measures how close the style of the predicted text is to the desired target style. A lower EMD here indicates that the predicted text closely matches the target style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "493dca1a-ff6d-4911-b85a-d6beec1b173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMD for Style Transfer Intensity (STI)\n",
    "\n",
    "# Here, 'source_label_0' and 'source_label_1' are the probabilities for the source text being neutral and subjective, respectively\n",
    "# Similarly for 'target_label_0', 'target_label_1', 'predicted_label_0', and 'predicted_label_1'\n",
    "\n",
    "emd_source_predicted = [wasserstein_distance([row[source_label_0_col], row[source_label_1_col]],\n",
    "                                              [row[predicted_label_0_col], row[predicted_label_1_col]])\n",
    "                        for index, row in df.iterrows()]\n",
    "emd_target_predicted = [wasserstein_distance([row[target_label_0_col], row[target_label_1_col]],\n",
    "                                              [row[predicted_label_0_col], row[predicted_label_1_col]])\n",
    "                        for index, row in df.iterrows()]\n",
    "\n",
    "# Calculate Content Preservation Score\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "source_embeddings = model.encode(df['source_text'].tolist())\n",
    "predicted_embeddings = model.encode(df['predictions'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becbaa40-3815-4d02-93f3-71058d78f306",
   "metadata": {},
   "source": [
    "## For Content Preservation Score (CPS) calculation\n",
    "\n",
    "**1. Compute Sentence Embeddings**\n",
    "\n",
    "SentenceTransformer Model: The code uses a pre-trained model from the sentence-transformers library, specifically 'bert-base-nli-mean-tokens'. This model is designed to produce meaningful sentence embeddings for a wide range of texts.\n",
    "\n",
    "Embeddings for Source and Predicted Texts: The model encodes both the source and predicted texts, converting them into high-dimensional vectors (embeddings) that represent their semantic content.\n",
    "\n",
    "**2. Calculate Cosine Similarity for Content Preservation**\n",
    "\n",
    "Cosine Similarity: This metric measures the cosine of the angle between two vectors. In the context of sentence embeddings, a higher cosine similarity indicates greater semantic similarity between texts.\n",
    "\n",
    "Iterative Comparison: The code iterates over each pair of source and predicted embeddings, calculating the cosine similarity for each pair. This value ranges from -1 to 1, where 1 means identical directionality (high semantic similarity), 0 indicates orthogonality (no similarity), and -1 implies completely opposite directionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2aa2c6a-84a8-41b4-8cf0-0265e886a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_scores = [1 - cosine(source_emb, pred_emb) \n",
    "                  if not np.isnan(cosine(source_emb, pred_emb)) else 0\n",
    "                  for source_emb, pred_emb in zip(source_embeddings, predicted_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804ae208-a99a-479c-b892-bfc312e6f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results in a new DataFrame\n",
    "evaluation_df = pd.DataFrame({\n",
    "    \"Source Text\": df['source_text'],\n",
    "    \"Target Text\": df['target_text'],\n",
    "    \"Predicted Text\": df['predictions'],\n",
    "    \"EMD Source-Predicted\": emd_source_predicted,\n",
    "    \"EMD Target-Predicted\": emd_target_predicted,\n",
    "    \"Content Preservation Score\": content_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db78b7c7-fa47-4261-9812-eff078bdce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Source Text  \\\n",
      "0  in april 2009 a brazilian human rights group, ...   \n",
      "1  the 51 day standoff and ensuing murder of 76 m...   \n",
      "2  mark oaten (born 8 march 1964, watford) is a d...   \n",
      "3  another infamous period of colonisation in anc...   \n",
      "4  photo sequence of astonishing 2005 chicagoland...   \n",
      "\n",
      "                                         Target Text  \\\n",
      "0  in april 2009 a brazilian human rights group, ...   \n",
      "1  the 51 day standoff and ensuing deaths of 76 m...   \n",
      "2  mark oaten (born 8 march 1964, watford) is a l...   \n",
      "3  another period of colonisation in ancient time...   \n",
      "4  photo sequence of 2005 chicagoland crash with ...   \n",
      "\n",
      "                                      Predicted Text  EMD Source-Predicted  \\\n",
      "0  in april 2009 a brazilian human rights group, ...              0.000000   \n",
      "1  the 51 day standoff and ensuing murder of 76 m...              0.000000   \n",
      "2  mark oaten (born 8 march 1964, watford) is a l...              0.037568   \n",
      "3  another period of colonisation in ancient time...              0.025609   \n",
      "4  photo sequence of 2005 chicagoland crash with ...              0.001016   \n",
      "\n",
      "   EMD Target-Predicted  Content Preservation Score  \n",
      "0              0.097619                    1.000000  \n",
      "1              0.148595                    1.000000  \n",
      "2              0.000000                    0.934390  \n",
      "3              0.000000                    0.851425  \n",
      "4              0.000000                    0.983531  \n"
     ]
    }
   ],
   "source": [
    "print(evaluation_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "489ab745-b30f-40c7-b538-65b965aca2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data saved to: ../../data/evaluated.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the evaluation DataFrame to a new CSV file\n",
    "evaluation_csv_path = \"../../data/evaluated.csv\"\n",
    "evaluation_df.to_csv(evaluation_csv_path, index=False)\n",
    "\n",
    "print(\"Evaluation data saved to:\", evaluation_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a279790",
   "metadata": {},
   "source": [
    "# Refined Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a163a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1e993c6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
